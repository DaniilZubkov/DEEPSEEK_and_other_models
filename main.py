from aiogram import Bot, Dispatcher
from aiogram.filters import Command
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.types import Message, FSInputFile
from aiogram.enums import ParseMode

import asyncio
from openai import OpenAI
import re



bot = Bot('')
dp = Dispatcher(storage=MemoryStorage())

# DEEPSEEK SETTINGS (Deepseek-r1-zero:free)
deepseek_client = OpenAI(api_key="", base_url="https://openrouter.ai/api/v1")
system_prompt = """ğŸ¤–âœ¨ You are an expert multilingual AI assistant and developer with extensive experience. Follow these advanced guidelines:

 ğŸŒ 1. Language Processing (Intelligent Multilingual Handling) ğŸ§ 
     - ğŸ” Perform 3-step language analysis:
       1ï¸âƒ£ 1. Detect primary language using linguistic patterns ğŸ•µï¸â™‚ï¸
       2ï¸âƒ£ 2. Identify secondary languages if code-mixing exceeds 30% ğŸŒ
       3ï¸âƒ£ 3. Recognize technical terms that should remain untranslated âš™ï¸
     - ğŸ“¢ Response language mirroring:
       * ğŸ¯ Match the user's primary language with 98% accuracy
       * ğŸ”’ Preserve original terminology for: proper nouns, technical terms, cultural concepts
       * ğŸŒˆ For mixed input (e.g., Hinglish, Spanglish), maintain the dominant language base

 ğŸ“ 2. Advanced Response Formatting (Structured & Precise) ğŸ¨
     - ğŸ—‚ Apply hierarchical organization:
       â€¢ ğŸš€ **<concise 15-word summary>**
       â€¢ ğŸ“Œ Supporting arguments (bullet points)
       â€¢ ğŸ’» Examples (indented code blocks if technical)
       â€¢ ğŸŒ Cultural/localization notes (italic when relevant)
     - â± Strict length management:
       * ğŸ“ Real-time character count including Markdown (max 4096)
       * âœ‚ï¸ Auto-truncation algorithm:
         - ğŸ”„ Preserve complete sentences
         - ğŸ¯ Prioritize core information
         - â• Add "[...]" if truncated
     - ğŸ­ Important style work (other Markdown and emojis):
       * ğŸ˜Š Use 3-5 relevant emojis per response section
       * ğŸ”€ Use different fonts (MARKDOWN + EMOJI combinations)

 ğŸ’¼ 3. Specialized Content Handling âš™ï¸
     - ğŸ‘¨ğŸ’» Technical material:
       > ğŸ”§ Maintain original English terms with localized explanations
       > ğŸ’» Use ```code blocks``` for all commands/APIs
     - ğŸŒ Cultural adaptation:
       * ğŸ“ Adjust measurements (metric/imperial)
       * ğŸ’° Localize examples (currency, idioms)
       * ğŸš¨ Recognize region-specific sensitivities

 âœ… 4. Quality Assurance Protocols ğŸ”
     - ğŸ”„ Run pre-response checks:
       1. ğŸ“š Language consistency validation
       2. ğŸ“Š Information density audit
       3. ğŸŒ Cultural appropriateness scan
     - ğŸ§ Post-generation review:
       * âœ”ï¸ Verify factual accuracy
       * ğŸš Ensure tone alignment (professional â†’ friendly spectrum)
       * ğŸ“– Confirm readability score >80%

 ğŸ“¤ Output template:
 ğŸš© **<Language-detected response>**
   â€¢ ğŸ¯ Key point 1
   â€¢ ğŸ”‘ Key point 2
   - ğŸ“ Supporting detail
   - ğŸ’¡ Example/excerpt
 ğŸŒ <cultural/localization note if relevant>



"""




def format_answer(answer: str) -> str:
    # ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ: Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ Ğ¿ÑƒĞ½ĞºÑ‚Ğ°Ğ¼
    return "\n\n".join(answer.split('\n'))

def clean_output(text):
    return re.sub(r'\\boxed\{([^}]*)\}', r'\1', text)


def clean_markdown(text: str) -> str:
    patterns = [
        # (r'```.*?\n(.*?)\n```', r'\1', re.DOTALL),
        (r'`(.*?)`', r'\1'),
        (r'\*\*(.*?)\*\*', r'*\1*'),  # Ğ–Ğ¸Ñ€Ğ½Ñ‹Ğ¹ â†’ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğ¹ Markdown
        (r'^#+\s*(.+)$', r'*\1*', re.MULTILINE),  # Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸ â†’ Ğ¶Ğ¸Ñ€Ğ½Ñ‹Ğ¹
    ]

    for pattern in patterns:
        if len(pattern) == 3:
            p, r, f = pattern
            text = re.sub(p, r, text, flags=f)
        else:
            p, r = pattern
            text = re.sub(p, r, text)

    return text


# def adaptive_context_window(task_type):
#     config = {
#         'code': {'max_length': 4096, 'rope_theta': 1e6},
#         'text': {'max_length': 2048, 'rope_theta': 1e4},
#         'math': {'max_length': 1024, 'rope_theta': 1e5}
#     }
#     return config[task_type]










@dp.message(Command('start'))
async def start(message: Message):
    black_photo_path = 'fotos/black_img.jpg'

    await message.answer_photo(photo=FSInputFile(black_photo_path), caption=f'ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, {message.from_user.first_name}. Ğ¯ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Deepseek Ğ² Ğ¢ĞµĞ»ĞµĞ³Ñ€Ğ°Ğ¼.\n\n'
                               f'')



@dp.message()
async def get_message(message: Message):
    completion = deepseek_client.chat.completions.create(
        extra_body={},
        model="deepseek/deepseek-r1-zero:free",
        messages=[
            {
                "role": "system",
                "content": system_prompt
            },
            {
                "role": "user",
                "content": message.text
            }
        ],
        temperature=0.7,  # ĞšĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ "ĞºÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸" (0â€“1)
        top_p=0.9,  # Ğ’Ğ»Ğ¸ÑĞµÑ‚ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²
        frequency_penalty=0.2,  # Ğ£Ğ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€ĞµĞ½Ğ¸Ñ
        presence_penalty=0.2,    # ĞŸĞ¾Ğ¾Ñ‰Ñ€ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ñ‚ĞµĞ¼Ñ‹
    )

    deepseek_answer = completion.choices[0].message.content

    print(deepseek_answer)
    print(clean_markdown(deepseek_answer))
    print(len(clean_output(clean_markdown(deepseek_answer))))

    new_deepseek_answer = clean_output(clean_markdown(deepseek_answer))


    if '`' in new_deepseek_answer[0:2] and '`' in new_deepseek_answer[-3:-1]:
        if len([char for char in new_deepseek_answer]) >= 4096:
            while new_deepseek_answer:
                await message.answer(new_deepseek_answer[:4096], parse_mode='MARKDOWN')
                # ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ğ¾Ğ¹ Ñ‡Ğ°ÑÑ‚Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°
                new_deepseek_answer = new_deepseek_answer[4096:]
        await message.answer(new_deepseek_answer[2:-3], parse_mode='MARKDOWN')

    if len([char for char in new_deepseek_answer]) >= 4096:
        while new_deepseek_answer:
            await message.answer(new_deepseek_answer[:4096], parse_mode='MARKDOWN')
            # ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ğ¾Ğ¹ Ñ‡Ğ°ÑÑ‚Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°
            new_deepseek_answer = new_deepseek_answer[4096:]

    await message.answer(new_deepseek_answer, parse_mode='MARKDOWN')







# POLLING
async def main():
    await dp.start_polling(bot)

if '__main__' == __name__:
    asyncio.run(main())