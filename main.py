from aiogram import Bot, Dispatcher, F, types
from aiogram.filters import Command
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.types import Message, FSInputFile
from aiogram.enums import ParseMode
from keyboards import main_keyboard

import asyncio
from openai import OpenAI
import re
from db import Database



bot = Bot('')
dp = Dispatcher(storage=MemoryStorage())
db = Database('database.db')



# DEEPSEEK SETTINGS (Deepseek-r1 qwen 32b) and other models
deepseek_client = OpenAI(api_key="", base_url="https://openrouter.ai/api/v1")



system_prompt = """ğŸ¤–âœ¨ You are an expert multilingual AI assistant and developer with extensive experience. Follow these advanced guidelines:

 ğŸŒ 1. Language Processing (Intelligent Multilingual Handling) ğŸ§ 
     - ğŸ” Perform 3-step language analysis:
       1ï¸âƒ£ 1. Detect primary language using linguistic patterns ğŸ•µï¸â™‚ï¸
       2ï¸âƒ£ 2. Identify secondary languages if code-mixing exceeds 30% ğŸŒ
       3ï¸âƒ£ 3. Recognize technical terms that should remain untranslated âš™ï¸
     - ğŸ“¢ Response language mirroring:
       * ğŸ¯ Match the user's primary language with 98% accuracy
       * ğŸ”’ Preserve original terminology for: proper nouns, technical terms, cultural concepts
       * ğŸŒˆ For mixed input (e.g., Hinglish, Spanglish), maintain the dominant language base

 ğŸ“ 2. Advanced Response Formatting (Structured & Precise) ğŸ¨
     - ğŸ—‚ Apply hierarchical organization:
       â€¢ ğŸš€ **<concise 15-word summary>**
       â€¢ ğŸ“Œ Supporting arguments (bullet points)
       â€¢ ğŸ’» Examples (indented code blocks if technical)
       â€¢ ğŸŒ Cultural/localization notes (italic when relevant)
     - â± Strict length management:
       * ğŸ“ Real-time character count including Markdown (max 4096)
       * âœ‚ï¸ Auto-truncation algorithm:
         - ğŸ”„ Preserve complete sentences
         - ğŸ¯ Prioritize core information
         - â• Add "[...]" if truncated
     - ğŸ­ Important style work (other Markdown and emojis):
       * ğŸ˜Š Use 3-5 relevant emojis per response section
       * ğŸ”€ Use different fonts (MARKDOWN + EMOJI combinations)

 ğŸ’¼ 3. Specialized Content Handling âš™ï¸
     - ğŸ‘¨ğŸ’» Technical material:
       > ğŸ”§ Maintain original English terms with localized explanations
       > ğŸ’» Use ```code blocks``` for all commands/APIs
     - ğŸŒ Cultural adaptation:
       * ğŸ“ Adjust measurements (metric/imperial)
       * ğŸ’° Localize examples (currency, idioms)
       * ğŸš¨ Recognize region-specific sensitivities

 âœ… 4. Quality Assurance Protocols ğŸ”
     - ğŸ”„ Run pre-response checks:
       1. ğŸ“š Language consistency validation
       2. ğŸ“Š Information density audit
       3. ğŸŒ Cultural appropriateness scan
     - ğŸ§ Post-generation review:
       * âœ”ï¸ Verify factual accuracy
       * ğŸš Ensure tone alignment (professional â†’ friendly spectrum)
       * ğŸ“– Confirm readability score >80%

 ğŸ“¤ Output template:
 ğŸš© **<Language-detected response>**
   â€¢ ğŸ¯ Key point 1
   â€¢ ğŸ”‘ Key point 2
   - ğŸ“ Supporting detail
   - ğŸ’¡ Example/excerpt
 ğŸŒ <cultural/localization note if relevant>



"""


allowed_models = {
    # DEEPSEEK family
    'Deepseek-R1': {
        'code': 'deepseek-r1',
        'api-key': 'API KEY',
    },
    'Deepseek-V3': {
        'code': 'deepseek-v3',
        'api-key': 'API KEY',
   },


   # GPT family
   'GPT-4 Turbo': {
        'code': 'gpt4-turbo',
        'api-key': 'API KEY',
   },
   'GPT-4.1': {
        'code': 'gpt4.1',
        'api-key': 'API KEY',
   },
   'GPT-4o': {
       'code': 'gpt4-o',
       'api-key': 'API KEY',
   },

   # MINI GPT`s family
   'GPT-4.1 Mini': {
       'code': 'gpt4.1-mini',
       'api-key': 'API KEY',
   },
   'GPT-4o Mini': {
       'code': 'gpt4-o-mini',
       'api-key': 'API KEY',
   },

   # CLAUDE family
   'Claude 3.7 Sonnet': {
       'code': 'claude3.7-sonnet',
       'api-key': 'API KEY',
   },
   'Claude 3.7 Sonnet (thinking)': {
       'code': 'claude3.7-sonnet-thinking',
       'api-key': 'API KEY',
   },

   # Open AI family
   'OpenAI o3': {
       'code': 'open-ai-o3',
       'api-key': 'API KEY',
   },
   'Open AI o4 Mini': {
       'code': 'open-ai-o4-mini',
       'api-key': 'API KEY',
   },


   # Gemini family
   'Gemini 2.0 Flash Lite': {
       'code': 'open-ai-o4-mini',
       'api-key': 'API KEY',
   },
}





def format_answer(answer: str) -> str:
    # ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ: Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ Ğ¿ÑƒĞ½ĞºÑ‚Ğ°Ğ¼
    return "\n\n".join(answer.split('\n'))

def clean_output(text):
    return re.sub(r'\\boxed\{([^}]*)\}', r'\1', text)


def clean_markdown(text: str) -> str:
    patterns = [
        # (r'```.*?\n(.*?)\n```', r'\1', re.DOTALL), Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑƒĞ±Ñ€Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ´ (ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾)
        # (r'`(.*?)`', r'\1'),
        (r'\*\*(.*?)\*\*', r'*\1*'),  # Ğ–Ğ¸Ñ€Ğ½Ñ‹Ğ¹ â†’ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğ¹ Markdown
        (r'^#+\s*(.+)$', r'*\1*', re.MULTILINE),  # Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸ â†’ Ğ¶Ğ¸Ñ€Ğ½Ñ‹Ğ¹
    ]

    for pattern in patterns:
        if len(pattern) == 3:
            p, r, f = pattern
            text = re.sub(p, r, text, flags=f)
        else:
            p, r = pattern
            text = re.sub(p, r, text)

    return text












@dp.message(Command('start'))
async def start(message: Message):
    try:
        db.create_tables()
        black_photo_path = 'fotos/black_img.jpg'

        if (not db.user_exists(message.from_user.id)):
            db.add_user(message.from_user.id)
            db.set_nickname(message.from_user.id, message.from_user.username)
            db.set_signup(message.from_user.id, 'done')

        await message.answer_photo(photo=FSInputFile(black_photo_path),
                                   caption=f'ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, {message.from_user.first_name}. Ğ¯ AI Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ğ² Telegram. Ğ£ Ğ¼ĞµĞ½Ñ ĞµÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:\n\n'
                                           f'***Ğ¢Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑˆÑŒ Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ ÑƒĞ´Ğ¾Ğ±Ğ½ÑƒÑ Ğ´Ğ»Ñ ÑĞµĞ±Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ğ¾ ĞºĞ½Ğ¾Ğ¿ĞºĞµ.*** ğŸ‘‡',
                                   parse_mode="MARKDOWN", reply_markup=main_keyboard())
    except Exception:
        pass





@dp.message()
async def get_message(message: Message):
    try:
        await message.answer(f'ğŸ› ï¸ ***ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ° Ğ¿Ğ¾Ğ´Ğ¾Ğ¶Ğ´Ğ¸Ñ‚Ğµ, {db.get_model(message.from_user.id)} Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²Ğ°Ñˆ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ...***', parse_mode="MARKDOWN")

        completion = deepseek_client.chat.completions.create(
            extra_body={},
            model="deepseek/deepseek-r1-distill-qwen-32b",
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": message.text
                }
            ],
            temperature=0.7,  # ĞšĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ "ĞºÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸" (0â€“1)
            top_p=0.9,  # Ğ’Ğ»Ğ¸ÑĞµÑ‚ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²
            frequency_penalty=0.2,  # Ğ£Ğ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€ĞµĞ½Ğ¸Ñ
            presence_penalty=0.2,  # ĞŸĞ¾Ğ¾Ñ‰Ñ€ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ñ‚ĞµĞ¼Ñ‹
        )

        deepseek_answer = completion.choices[0].message.content

        print(deepseek_answer)
        print(clean_markdown(deepseek_answer))
        print(len(clean_output(clean_markdown(deepseek_answer))))

        new_deepseek_answer = clean_output(clean_markdown(deepseek_answer))

        # if '`' in new_deepseek_answer[0:2] and '`' in new_deepseek_answer[-3:-1]:
        #     if len([char for char in new_deepseek_answer]) >= 4096:
        #         while new_deepseek_answer:
        #             await message.answer(new_deepseek_answer[:4096], parse_mode='MARKDOWN')
        #             # ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ğ¾Ğ¹ Ñ‡Ğ°ÑÑ‚Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°
        #             new_deepseek_answer = new_deepseek_answer[4096:]
        #     await message.answer(new_deepseek_answer[2:-3], parse_mode='MARKDOWN')

        if len([char for char in new_deepseek_answer]) >= 4096:
            while new_deepseek_answer:
                await message.answer(new_deepseek_answer[:4096], parse_mode='MARKDOWN')
                # ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ğ¾Ğ¹ Ñ‡Ğ°ÑÑ‚Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°
                new_deepseek_answer = new_deepseek_answer[4096:]

        await message.answer(new_deepseek_answer, parse_mode='MARKDOWN')


    except Exception:
        pass



@dp.callback_query(lambda F: True)
async def change_model(message: Message, callback_query: types.CallbackQuery):
    black_photo_path = 'fotos/black_img.jpg'

    try:
        if callback_query.data == 'change_model':
            await message.delete()
            await message.answer_photo(photo=FSInputFile(black_photo_path),
                                       caption=f'ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, {message.from_user.first_name}. Ğ¯ AI Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ğ² Telegram. Ğ£ Ğ¼ĞµĞ½Ñ ĞµÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:\n\n'
                                               f'***Ğ¢Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑˆÑŒ Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ ÑƒĞ´Ğ¾Ğ±Ğ½ÑƒÑ Ğ´Ğ»Ñ ÑĞµĞ±Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ğ¾ ĞºĞ½Ğ¾Ğ¿ĞºĞµ.*** ğŸ‘‡',
                                       parse_mode="MARKDOWN", reply_markup=main_keyboard())

    except Exception:
        pass





# POLLING
async def main():
    await dp.start_polling(bot)

if '__main__' == __name__:
    asyncio.run(main())